{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구현에 사용할 패키지 임포트하기\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 초기 상태의 미로 모습\n",
    "\n",
    "# 전체 그림의 크기 및 그림을 나타내는 변수 선언\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 붉은 벽 그리기\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "# 상태를 의미하는 문자열(S0~S8) 표시\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "# 그림을 그릴 범위 및 눈금 제거 설정\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                labelbottom=False, right=False, left=False, labelleft=False)\n",
    "\n",
    "# S0에 녹색 원으로 현재 위치를 표시\n",
    "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정책을 결정하는 파라미터의 초깃값 theta_0를 설정\n",
    "\n",
    "# 줄은 상태 0~7, 열은 행동방향(상,우,하,좌 순)를 나타낸다\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
    "                    [np.nan, 1, np.nan, 1],  # s1\n",
    "                    [np.nan, np.nan, 1, 1],  # s2\n",
    "                    [1, 1, 1, np.nan],  # s3\n",
    "                    [np.nan, np.nan, 1, 1],  # s4\n",
    "                    [1, np.nan, np.nan, np.nan],  # s5\n",
    "                    [1, np.nan, np.nan, np.nan],  # s6\n",
    "                    [1, 1, np.nan, np.nan],  # s7、※s8은 목표지점이므로 정책이 없다\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정책 파라미터 theta_0을 무작위 행동 정책 pi로 변환하는 함수\n",
    "\n",
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    '''단순 비율 계산'''\n",
    "\n",
    "    [m, n] = theta.shape  # theta의 행렬 크기를 구함\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m):\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :])  # 비율 계산\n",
    "\n",
    "    pi = np.nan_to_num(pi)  # nan을 0으로 변환\n",
    "\n",
    "    return pi\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ε-greedy 알고리즘 구현\n",
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "\n",
    "    # 행동을 결정\n",
    "    if np.random.rand() < epsilon:\n",
    "        # 확률 ε로 무작위 행동을 선택함\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # Q값이 최대가 되는 행동을 선택함\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "\n",
    "    # 행동을 인덱스로 변환\n",
    "    if next_direction == \"up\":\n",
    "        action = 0\n",
    "    elif next_direction == \"right\":\n",
    "        action = 1\n",
    "    elif next_direction == \"down\":\n",
    "        action = 2\n",
    "    elif next_direction == \"left\":\n",
    "        action = 3\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    next_direction = direction[a]  # 행동 a의 방향\n",
    "\n",
    "    # 행동으로 다음 상태를 결정\n",
    "    if next_direction == \"up\":\n",
    "        s_next = s - 3  # 위로 이동하면 상태값이 3 줄어든다\n",
    "    elif next_direction == \"right\":\n",
    "        s_next = s + 1  # 오른쪽으로 이동하면 상태값이 1 늘어난다\n",
    "    elif next_direction == \"down\":\n",
    "        s_next = s + 3  # 아래로 이동하면 상태값이 3 늘어난다\n",
    "    elif next_direction == \"left\":\n",
    "        s_next = s - 1  # 왼쪽으로 이동하면 상태값이 1 줄어든다\n",
    "\n",
    "    return s_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsa 알고리즘으로 행동가치 함수 Q를 수정\n",
    "def Sarsa(s, a, r, s_next, a_next, Q, eta, gamma):\n",
    "    if s_next == 8:  # 목표 지점에 도달한 경우\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "    else:\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sarsa 알고리즘으로 미로를 빠져나오는 함수, 상태 및 행동 그리고 Q값의 히스토리를 출력한다\n",
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0  # 시작 지점\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)  # 첫 번째 행동\n",
    "    s_a_history = [[0, np.nan]]  # 에이전트의 행동 및 상태의 히스토리를 기록하는 리스트\n",
    "\n",
    "    while (1):  # 목표 지점에 이를 때까지 반복\n",
    "        a = a_next  # 행동 결정\n",
    "\n",
    "        s_a_history[-1][1] = a\n",
    "        # 현재 상태(마지막이므로 인덱스가 -1)을 히스토리에 추가\n",
    "\n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        # 다음 단계의 상태를 구함\n",
    "\n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 다음 상태를 히스토리에 추가, 행동은 아직 알 수 없으므로 nan으로 둔다\n",
    "\n",
    "        # 보상을 부여하고 다음 행동을 계산함\n",
    "        if s_next == 8:\n",
    "            r = 1  # 목표 지점에 도달했다면 보상을 부여\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 다음 행동 a_next를 계산\n",
    "\n",
    "        # 가치함수를 수정\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "\n",
    "        # 종료 여부 판정\n",
    "        if s_next == 8:  # 목표 지점에 도달하면 종료\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "\n",
    "    return [s_a_history, Q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 무작위 행동정책 pi_0을 계산\n",
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)\n",
    "\n",
    "# 행동가치 함수 Q의 초기 상태\n",
    "[a, b] = theta_0.shape  # 열과 행의 갯수를 변수 a, b에 저장\n",
    "Q = np.random.rand(a, b) * theta_0\n",
    "# * theta0 로 요소 단위 곱셈을 수행, Q에서 벽 방향으로 이동하는 행동에는 nan을 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에피소드: 1\n",
      "0.1750448669244134\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 2\n",
      "0.1524397953977082\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 3\n",
      "0.15913537640189757\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 4\n",
      "0.35485054657878157\n",
      "목표 지점에 이르기까지 걸린 단계 수는 48단계입니다\n",
      "에피소드: 5\n",
      "0.07336784750514402\n",
      "목표 지점에 이르기까지 걸린 단계 수는 12단계입니다\n",
      "에피소드: 6\n",
      "0.05613312197691167\n",
      "목표 지점에 이르기까지 걸린 단계 수는 8단계입니다\n",
      "에피소드: 7\n",
      "0.037286345493245054\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 8\n",
      "0.04770425369593667\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 9\n",
      "0.03588965096228047\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 10\n",
      "0.042937881605617845\n",
      "목표 지점에 이르기까지 걸린 단계 수는 6단계입니다\n",
      "에피소드: 11\n",
      "0.0350846621390708\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 12\n",
      "0.032741813643547\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 13\n",
      "0.0313431565404797\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 14\n",
      "0.030745550931861598\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 15\n",
      "0.030001039401980845\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 16\n",
      "0.029127693176879244\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 17\n",
      "0.028144425454238453\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 18\n",
      "0.027070217725406742\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 19\n",
      "0.026252947023654993\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 20\n",
      "0.02597559457287424\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 21\n",
      "0.025659425873597153\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 22\n",
      "0.025304841910556042\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 23\n",
      "0.02491289636460159\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 24\n",
      "0.024485193475409228\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 25\n",
      "0.024023789875024182\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 26\n",
      "0.02353110228126043\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 27\n",
      "0.023009822289398296\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 28\n",
      "0.02246283899126278\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 29\n",
      "0.02189316975722222\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 30\n",
      "0.021303899217613442\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 31\n",
      "0.020698126257756244\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 32\n",
      "0.02007891868021383\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 33\n",
      "0.019449275076921846\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 34\n",
      "0.018812093382020056\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 35\n",
      "0.018170145535222115\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 36\n",
      "0.017526057668397654\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 37\n",
      "0.016882295229054378\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 38\n",
      "0.016241152468947084\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 39\n",
      "0.015604745750394167\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 40\n",
      "0.014975010154022472\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 41\n",
      "0.014353698907232815\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 42\n",
      "0.013742385190761763\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 43\n",
      "0.013142465919886992\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 44\n",
      "0.012555167135927636\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 45\n",
      "0.011981550681914643\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 46\n",
      "0.011422521873016067\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 47\n",
      "0.010878837907079553\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 48\n",
      "0.01035111679320988\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 49\n",
      "0.009839846606459202\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 50\n",
      "0.009345394904411108\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 51\n",
      "0.008868018166653502\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 52\n",
      "0.008407871140924783\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 53\n",
      "0.007965016000158198\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 54\n",
      "0.007539431232852056\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 55\n",
      "0.007131020205294325\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 56\n",
      "0.006739619348299142\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 57\n",
      "0.006365005933438916\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 58\n",
      "0.006006905414410846\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 59\n",
      "0.005664998318311798\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 60\n",
      "0.005338926679375633\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 61\n",
      "0.005028300014248588\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 62\n",
      "0.004732700843332216\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 63\n",
      "0.004451689767162925\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 64\n",
      "0.004184810110402171\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 65\n",
      "0.0039315921488443095\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 66\n",
      "0.0036915569370218337\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 67\n",
      "0.0034642197555924126\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 68\n",
      "0.0032490931988017335\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 69\n",
      "0.003045689923005801\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 70\n",
      "0.0028535250775724164\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 71\n",
      "0.0026721184395134268\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 72\n",
      "0.002500996272998268\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 73\n",
      "0.0023396929344751127\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 74\n",
      "0.002187752243564711\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 75\n",
      "0.0020447286391823694\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 76\n",
      "0.00191018813954702\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 77\n",
      "0.0017837091238687153\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 78\n",
      "0.0016648829525819364\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 79\n",
      "0.0015533144420440959\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 80\n",
      "0.0014486222086554923\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 81\n",
      "0.0013504388963836433\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 82\n",
      "0.0012584113007274578\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 83\n",
      "0.0011722004012081344\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 84\n",
      "0.001091481313570175\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 85\n",
      "0.0010159431719847234\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 86\n",
      "0.0009452889507096662\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 87\n",
      "0.0008792352338470311\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 88\n",
      "0.0008175119410742671\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 89\n",
      "0.0007598620165011338\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 90\n",
      "0.0007060410871206901\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 91\n",
      "0.0006558170966841637\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 92\n",
      "0.0006089699202348475\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 93\n",
      "0.0005652909639785042\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 94\n",
      "0.0005245827546516146\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 95\n",
      "0.00048665852208118476\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 96\n",
      "0.00045134177818062504\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 97\n",
      "0.00041846589523308886\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 98\n",
      "0.00038787368594350724\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 99\n",
      "0.0003594169874010511\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n",
      "에피소드: 100\n",
      "0.00033295625079343694\n",
      "목표 지점에 이르기까지 걸린 단계 수는 4단계입니다\n"
     ]
    }
   ],
   "source": [
    "# Sarsa 알고리즘으로 미로 빠져나오기\n",
    "\n",
    "eta = 0.1  # 학습률\n",
    "gamma = 0.9  # 시간할인율\n",
    "epsilon = 0.5  # ε-greedy 알고리즘 epsilon 초깃값\n",
    "v = np.nanmax(Q, axis=1)  # 각 상태마다 가치의 최댓값을 계산\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "while is_continue:  # is_continue의 값이 False가 될 때까지 반복\n",
    "    print(\"에피소드: \" + str(episode))\n",
    "\n",
    "    # ε 값을 조금씩 감소시킴\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # Sarsa 알고리즘으로 미로를 빠져나온 후, 결과로 나온 행동 히스토리와 Q값을 변수에 저장\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "\n",
    "    # 상태가치의 변화\n",
    "    new_v = np.nanmax(Q, axis=1)  # 각 상태마다 행동가치의 최댓값을 계산\n",
    "    print(np.sum(np.abs(new_v - v)))  # 상태가치 함수의 변화를 출력\n",
    "    v = new_v\n",
    "\n",
    "    print(\"목표 지점에 이르기까지 걸린 단계 수는 \" + str(len(s_a_history) - 1) + \"단계입니다\")\n",
    "\n",
    "    # 100 에피소드 반복\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
